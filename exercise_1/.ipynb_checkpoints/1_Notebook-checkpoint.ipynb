{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Backpropagation\n",
    "\n",
    "The backpropagation algorithm allows the information from the loss flowing backward through the network in order to compute the gradient of the loss function $L$ w.r.t the weights $w$ of the model. \n",
    "\n",
    "The key idea of backpropagation is decomposing the derivatives by applying the chain rule to the loss function.\n",
    "\n",
    "$$ \\frac{\\partial L}{\\partial w} = \\frac{\\partial L}{\\partial \\hat y} \\cdot \\frac{\\partial \\hat y}{\\partial w}$$\n",
    "\n",
    "### Backward Pass\n",
    "\n",
    "The backward pass consists of computing the derivative $\\frac{\\partial \\hat y}{\\partial w}$. Again, we can decompose this derivative by the chain rule: For $s = X \\cdot w$ we obtain\n",
    "\n",
    "$$\\frac{\\partial \\hat y}{\\partial w} = \\frac{\\partial \\sigma(s)}{\\partial w} = \\frac{\\partial \\sigma(s)}{\\partial s} \\cdot \\frac{\\partial s}{\\partial w}$$\n",
    "\n",
    "\n",
    "**Hint:** Taking track of the dimensions in higher-dimensional settings can make the task a little bit complicated. Make sure you understand the operations here. If you have difficulties, then first try to understand the forward and backward pass with a single input consisting of $D+1$ features. In that case our data matrix has the dimension $X \\in \\mathbb{R}^{1 \\times (D+1)}$. After you have understood this situation, you can go back to the setting where our data matrix has dimension $X \\in \\mathbb{R}^{N \\times (D+1)}$ and consists of $N$ samples each having $D+1$ features.\n",
    "\n",
    "**Hint 2**: It is helpful to follow the [TUM article][] (Section 3) calculating the chain-rule, while dealing with matrix notations:\n",
    "\n",
    "**Note**: If $X$ is of shape $N\\times D$, then in this exercise it is $N\\times (D+1)$, as we concatanate the affine layer's bias term to it, instead of having a different variable.\n",
    "\n",
    "[TUM article]: https://bit.ly/tum-article \"Article\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
